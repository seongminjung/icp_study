# ICP 연구 보고서

## 목차

1. 서론
2. 연구 방법
   1. 데이터 전처리
      1. 복셀화 및 해시 함수
      2. 수직선 및 면 추출
   2. ICP 알고리즘
      1. 다운샘플링
      2. Closest Point 찾기
      3. 변환 행렬 계산
3. 실험
   1. 실험 환경
      1. 데이터셋
      2. 베이스라인
   2. 평가 지표
   3. 결과
4. 결론

## 1. 서론

ICP(Iterative Closest Point) 알고리즘은 두 개의 3D point cloud 데이터 점군을 매칭하는 알고리즘으로, pose estimation, loop closure 등에 사용되는 알고리즘이다. 두 점군의 각 점들을 매칭하여 두 점군의 변환 행렬을 찾아내는 알고리즘으로 정확도가 높은 알고리즘 중 하나이다. 하지만 ICP 알고리즘은 매칭하는 두 점군의 크기가 클 경우 연산량이 매우 많아지며, feature가 부족한 경우 sliding 현상이 발생하는 등 정확도가 떨어지는 문제가 있다.

일반적인 ICP 알고리즘에 비해, 자율주행차나 지상 로봇 등은 연속된 두 point cloud 간 constraint가 존재한다. 따라서 로봇 이동의 자유도, 가속도, 회전 반경 등을 고려하여 알고리즘을 효율적으로 개선할 수 있다.

본 연구는 자율주행차나 지상 로봇 중에서도 도심 환경에 초점이 맞춰져 있다. 도심 속 가로등, 나무 등 길고 지면에 수직인 물체는 효율적인 랜드마크로 사용된다는 것에서 착안했다. 이에 따라, 3D point cloud 데이터에서 지면에 수직인 선과 면 성분을 고속으로 추출하고 이를 이용해 더 효과적인 매칭을 하는 알고리즘을 개발하였다. KITTI 데이터셋에서 기존의 ICP 알고리즘에 비해 정확도를 개선하면서 2배 빠른 결과를 얻었다.

## 2. 연구 방법

### 2.1. 데이터 전처리

데이터 전처리 과정에서는 3D point cloud로부터 지면에 수직인 선과 면 성분을 고속으로 추출한다. 지표면에서만 움직이는 로봇의 경우 높이가 있는 물체는 주변에 비해 뚜렷하게 구분되기 때문이다. 이러한 수직 성분들은 (x, y) 좌표와 높이로 분리되어 저장되고, 2D ICP에 높이를 가중치로 취한 방식으로 매칭이 이루어진다. 이를 통해 z축 방향의 움직임은 추정할 수 없지만, 지상이나 실내 환경에서는 더욱 효율적이고 정확하게 pose 추정을 할 수 있다.

#### 2.1.1. 복셀화 및 해시 함수

3D point cloud를 복셀화한 후, 각 복셀의 좌표에 해시 함수를 적용하여 중복된 복셀을 제거하고 4바이트의 int 변수에 저장한다. 복셀의 크기는 한 변이 0.2m인 정육면체로 설정하였고, 복셀의 위치는 cluster-based가 아닌 grid-based로 설정하여 수직선과 면 추출을 용이하게 하였다. 해시 함수는 복셀의 x, y, z 좌표를 그대로 2진수로 변환하고 10비트씩 이어붙여 총 30비트의 int 변수로 변환하는 방식을 사용하였다. 이 방식을 통해 해시 충돌을 원천적으로 방지하면서 비트 연산만으로 연속된 복셀을 찾아낼 수 있다. 이때 이어붙이는 순서는 [y, x, z] 순서로 하였는데, 이는 2.1.2에서 설명할 수직선 및 면 추출 과정에서의 우선순위를 고려한 것이다.

$$
\text{hash} = (y \ll 20) + (x \ll 10) + z
$$

KITTI 데이터셋 9번 시퀀스의 첫 프레임을 복셀화한 결과는 아래와 같다. 우측 이미지는 복셀의 hash 값에 비레하여 색조를 변화시킨 것이다. [y, x, z] 순서로 hash 값을 이어붙였으므로, 좌우 방향인 y축 방향으로 색조가 가장 빠르게 변하며 높이 방향인 z축 방향으로는 색조가 거의 같은 것을 확인할 수 있다.

| Raw Point Cloud |    Voxelized    |
| :-------------: | :-------------: |
| ![](./img1.png) | ![](./img2.png) |

#### 2.1.2. 수직선 및 면 추출

해시 함수를 적용한 복셀 데이터를 이용하여 매 프레임마다 z방향 수직선과 지표면에 수직인 평면을 추출한다. 우선 해시값을 기준으로 복셀을 정렬한다. 해시값의 최하위 10비트가 z좌표이므로, 해시값의 차이가 1인 복셀은 z축 방향으로 연속된 복셀이다. 따라서 비트 연산을 이용해 빠르게 연속인 복셀들을 찾아낸다. 이때, 수직선은 5개 이상의 연속된 복셀로 구성되어야 한다는 조건을 추가하여 높이가 1m 이상인 물체만을 선별했다. 이후, 수직선의 x, y 좌표만을 실제 매칭이 이루어지는 데이터로 저장하며 수직선의 높이는 매칭 과정에서 가중치로 활용되므로 따로 저장한다. 수직선을 이루지 못한 복셀들은 바닥면이나 중요도가 낮은 물체로 판단하여 제거한다. 아래와 같은 형식으로 Eigen Matrix와 Vector에 각각 저장한다.

$$
\begin{align*}
\text{Lines} & : \begin{bmatrix} x_1 & x_2 & \dots \\ y_1 & y_2 & \dots \end{bmatrix} \\
\text{Heights} & : \begin{bmatrix} h_1 \\ h_2 \\ \vdots \end{bmatrix}
\end{align*}
$$

평면 또한 수직선과 같은 방식으로 추출한다. 이때 x축과 나란한 평면만을 추출하는데, 로봇의 진행 방향인 x축과 나란한 평면은 sliding을 유발할 가능성이 가장 높기 때문이다. 이러한 평면을 하나의 개체로 저장하고 별도의 매칭 constrant를 적용함으로써 sliding을 효과적으로 방지한다. x축과 나란하지 않은 평면은 sliding을 적게 유발하므로 모든 각도의 평면을 추출하는 것보다 직접 매칭 과정에서 찾아내는 것이 효율적이라고 판단하였다.

해시값에 10만큼 right shift 연산을 적용하여 z좌표를 제거하고 x좌표를 최하위 10비트로 둔다. 이후 수직선 추출과 동일한 방식으로 해시값을 비교해 x축 방향으로 연속된 수직선을 찾아내고, 이를 평면이라는 하나의 개체로 묶는다. 평면이 시작하는 (x, y) 좌표와 끝나는 좌표, 평면을 이루는 수직선들의 평균 높이를 하나의 Eigen Matrix에 저장한다.

$$
\begin{align*}
\text{Planes} & : \begin{bmatrix} x_{1, start} & x_{2, start} & \dots \\ y_{1, start} & y_{2, start} & \dots \\ x_{1, end} & y_{2, end} & \dots \\ y_{1, end} & y_{2, end} & \dots \\ h_1 & h_2 & \dots \end{bmatrix} \\
\end{align*}
$$

KITTI 데이터셋 9번 시퀀스의 첫 프레임에서 수직선과 평면을 추출한 결과는 아래와 같다. 수직선은 흰색, 평면은 노란색으로 표시되었으며, 좌측 이미지는 수직선만 추출했을 때의 결과, 우측 이미지는 수직선과 평면을 모두 추출했을 때의 결과이다. 상단의 긴 평면의 경우 하나의 평면이 수직선 수십 개를 대체하고 있음을 확인할 수 있다.

|   Only Lines    | Lines and Planes |
| :-------------: | :--------------: |
| ![](./img3.png) | ![](./img4.png)  |

### 2.2. ICP 알고리즘

3차원 공간을 다루지만 2차원 ICP 알고리즘을 변형한 방식을 사용한다. 수직선과 평면을 각각 2차원에서의 점과 선으로 간주하고, 높이는 가중치로 취하여 매칭을 진행한다. 앞으로의 설명에서 편의를 위해 수직선-수직선 매칭은 점대점, 수직선-평면 매칭은 점대선 매칭으로 칭하도록 하겠다. 평면을 구성하는 수직선들 각각에 대해 매칭 여부를 계산하는 것이 아니라 평면이라는 하나의 객체에 대해 판단하기 때문에 정확도와 효율성을 동시에 확보할 수 있다.

#### 2.2.1. 다운샘플링

약 10만 개의 data point로 이루어진 point cloud의 경우 수백 개의 수직선들이 추출된다. 차원의 감소까지 고려하면 연산량이 큰 폭으로 줄어들지만 실시간성을 확보하기 위해서는 다운샘플링이 필요하다. 4.x.x에서 보인 것과 같이 가장 효율적인 비율인 5%를 적용하여 매 iteration마다 원본 데이터에서 새롭게 다운샘플링을 진행한다. 이때 수직선에 대해서만 다운샘플링을 진행한다.

#### 2.2.2. Closest Point 찾기

다운샘플링된 현재 프레임과 직전 프레임간 거리가 가장 가까운 점들의 쌍을 찾는다. 이때 직전 프레임의 경우 로봇 위치를 중심으로 50m 반경 내의 점과 선만을 이용한다. 점대점 거리 비교는 2차원에서의 ICP과 동일하다. 현재 프레임의 점 각각에 대하여 직전 프레임의 모든 점까지의 거리를 계산하고, 거리가 가장 가까운 쌍을 찾는다. 점대선 거리 비교의 경우, 현재 프레임의 각 점에서 map의 모든 선에 내린 수선의 발까지의 거리를 비교한다. 이때 수선의 발이 해당 선을 벗어난 위치에 있을 경우 그 선은 무시한다. 이후 점으로부터 수선의 발까지의 거리가 가장 가까운 선을 찾는다. 최종적으로 점대점 거리와 점대선 거리를 비교하여 점대점 거리가 더 작을 경우 해당 점을, 점대선 거리가 더 가까운 경우 수선의 발의 위치를 closest point로 선택한다. 아래와 같이 현재 프레임의 점들은 $\mathbf{X}$, 직전 프레임의 점들은 $\mathbf{Y}$로 표기한다.

$$
\begin{align*}
\mathbf{X} & = \{ x_1, \ x_2, \dots, \ x_n\} \\
\mathbf{Y} & = \{ y_1, \ y_2, \dots, \ y_n\}
\end{align*}
$$

#### 2.2.3. 변환 행렬 계산

다운샘플링된 현재 프레임의 모든 점에 대하여 closest point를 찾았다면, Singular Value Decomposition을 이용하여 두 점군 간의 변환 행렬을 계산할 수 있다. 이때 계산 과정에서 수직선과 평면의 높이가 가중치로 활용된다. 물체의 높이가 높을수록 그 안에 포함되는 라이다 data point들도 많으므로, 일반 ICP에서 각 data point들을 모두 계산한 것과 같은 효과를 내기 위함이다.

우선 outlier rejection을 위해 두 점 사이의 거리가 상위 5%인 쌍을 매칭에서 제외된다. 이후 아래의 수식을 이용하여 현재 프레임과 직전 프레임의 무게중심을 계산한다. 이 단계에서는 수직선과 평면의 높이를 가중치로 취하지 않는 것이 정확도가 높은 것으로 나타났다.

$$
\begin{align*}
x_0 & = \frac{1}{N} \sum_{i=1}^{N} x_i \\
y_0 & = \frac{1}{N} \sum_{i=1}^{N} y_i
\end{align*}
$$

이후 각 점에 대해 무게중심의 좌표를 빼줌으로써 각 점의 중심이 원점에 위치하도록 한다.

$$
\begin{align*}
x_i - x_0 \\
y_i - y_0
\end{align*}
$$

이제 $\mathbf{X}$와 $\mathbf{Y}$간의 covariance matrix $\mathbf{H}$를 계산한다. 이때 수직선과 평면의 높이를 가중치 벡터 $\mathbf{h}$로 취하여 계산에 반영한다.

$$
\begin{gather*}
\mathbf{h} = \begin{bmatrix} h_1 \\ h_2 \\ \vdots \\ h_n \end{bmatrix} \\
\mathbf{H} = \sum h_i(\mathbf{x}_i - \mathbf{x}_0)(\mathbf{y}_i - \mathbf{y}_0)^T = \mathbf{X} \cdot diag(\mathbf{h}) \cdot \mathbf{Y} \\
\end{gather*}
$$

계산된 covariance matrix $\mathbf{H}$를 Singular Value Decomposition하여 회전 행렬 $\mathbf{R}$과 변환 벡터 $\mathbf{t}$를 계산한다.

$$
\begin{align*}
\mathbf{H} & = \mathbf{U} \mathbf{D} \mathbf{V}^T \\
\mathbf{R} & = \mathbf{V} \mathbf{U}^T \\
\mathbf{t} & = \mathbf{y}_0 - \mathbf{R} \mathbf{x}_0
\end{align*}
$$

## 3. 실험

### 3.1. 실험 환경

#### 3.1.1. 데이터셋

본 연구는 KITTI 데이터셋을 이용하여 실험을 진행하였다. KITTI 데이터셋은 도심 환경에서 촬영된 라이다 데이터로, 자율주행차나 지상 로봇의 pose estimation 등에 널리 사용되는 데이터셋이다. 본 연구에서는 KITTI 데이터셋의 09번 시퀀스를 사용하였으며, 10Hz의 라이다 데이터를 1Hz로 속도를 낮추어 사용하였다.

#### 3.1.2. 베이스라인

본 연구에서는 기존의 3D ICP 알고리즘을 베이스라인으로 삼았다. 복셀화나 수직선 추출 등의 전처리 과정 없이 3D point cloud 데이터를 그대로 사용하여 매칭을 진행하였다.

### 3.2. 평가 지표

본 연구에서는 기존 ICP 알고리즘, 변형한 ICP 알고리즘을 통해 추정한 pose와 ground truth pose를 각각 비교한 RMSE를 평가 지표로 사용하였다. 이때 z축 방향의 움직임은 추정할 수 없으므로 x, y 좌표만을 사용하여 RMSE를 계산하였다.

$$
\text{RMSE} = \sqrt{\frac{1}{N} \sum_{i=1}^{N} (x_i - \hat{x}_i)^2 + (y_i - \hat{y}_i)^2}
$$

한 프레임을 처리하는 데 걸리는 시간도 평가 지표로 사용하였다.

### 3.3. 결과

## 4. 결론
